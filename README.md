# InfoWatchdog - Agent de Veille Environnementale

Agent automatique de collecte et de veille d'actualitÃ©s environnementales depuis multiple sources (Reddit, RSS) avec stockage structurÃ© dans Airtable.

## ğŸ¯ Objectif

InfoWatchdog surveille automatiquement l'actualitÃ© environnementale en collectant des contenus rÃ©cents depuis diverses sources et les stocke de maniÃ¨re structurÃ©e pour faciliter l'analyse et le suivi des tendances.

## ğŸ“– Documentation

- **[Configuration Airtable](docs/airtable_setup.md)** - Guide complet pour configurer Airtable
- **[Structure du projet](docs/structure.md)** - Architecture et organisation des fichiers

## ğŸŒ± Sources de DonnÃ©es

### Reddit
- **Subreddits surveillÃ©s** : `environment`, `climate`, `sustainability`, `renewableenergy`, `ClimateChange`, `solar`, `wind`
- **Collecte** : Posts les plus populaires et rÃ©cents
- **Filtrage** : Pertinence environnementale automatique

### RSS Feeds
- **CleanTechnica** - ActualitÃ©s cleantech et Ã©nergies renouvelables
- **TreeHugger** - Environnement et dÃ©veloppement durable
- **GreenTech Media** - Technologies vertes
- **Yale Environment 360** - Analyses environnementales
- **Environmental Leader** - Business et environnement
- **Carbon Brief** - Changement climatique et Ã©nergie

## ğŸ“Š Format des DonnÃ©es

Chaque article collectÃ© contient :
- **Titre** et **URL** source
- **Contenu/RÃ©sumÃ©** (extrait)
- **Source** et **Auteur**
- **Date de publication** et **Date de collecte**
- **Tags/Mots-clÃ©s** automatiques
- **MÃ©tadonnÃ©es** spÃ©cifiques (score Reddit, catÃ©gories RSS, etc.)
- **Hash unique** pour Ã©viter les doublons

## ğŸ›  Installation

### PrÃ©requis
- Python 3.8+
- Compte Reddit (pour API)
- Compte Airtable

### 1. Cloner le projet
```bash
git clone https://github.com/yemal22/info-watchdog.git
cd info-watchdog
```

### 2. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 3. Configuration des APIs

#### Reddit API
1. Allez sur [Reddit Apps](https://www.reddit.com/prefs/apps)
2. CrÃ©ez une nouvelle application (type "script")
3. Notez le `client_id` et `client_secret`

#### Airtable
âš ï¸ **Important** : Les champs Airtable doivent Ãªtre crÃ©Ã©s manuellement avant utilisation.

**Configuration rapide :**
1. CrÃ©ez une base Airtable avec une table "Environmental_News"
2. Ajoutez les champs requis (voir [guide dÃ©taillÃ©](docs/airtable_setup.md))
3. RÃ©cupÃ©rez votre API key et Base ID

**Champs obligatoires :**
- `Title` (Single line text)
- `URL` (URL) 
- `Source` (Single line text)
- `Content` (Long text)
- `Author` (Single line text)
- `Published_Date` (Date)
- `Collected_Date` (Date)
- `Collector` (Single line text)
- `Hash` (Single line text)
- `Tags` (Single line text)

**Champs optionnels (Reddit) :**
- `Reddit_Score` (Number)
- `Reddit_Comments` (Number)
- `Subreddit` (Single line text)

â¡ï¸ **[Guide complet de configuration Airtable](docs/airtable_setup.md)**

### 4. Variables d'environnement
```bash
cp .env.example .env
```

Ã‰ditez le fichier `.env` :
```bash
# Reddit API
REDDIT_CLIENT_ID=votre_client_id
REDDIT_CLIENT_SECRET=votre_client_secret
REDDIT_USER_AGENT=InfoWatchdog/1.0

# Airtable
AIRTABLE_API_KEY=votre_api_key
AIRTABLE_BASE_ID=votre_base_id
AIRTABLE_TABLE_NAME=Environmental_News
```

## ğŸš€ Utilisation

### Test de configuration
```bash
python run.py --test-only
```

### Collecte unique
```bash
python run.py
```

### Afficher les statistiques
```bash
python run.py --stats
```

### Configuration personnalisÃ©e
```bash
python run.py --config config/custom.yaml
```

## âš™ï¸ Configuration

Le fichier `config/config.yml` permet de personnaliser :

### Collecteurs Reddit
```yaml
collectors:
  reddit:
    enabled: true
    subreddits: ["environment", "climate", "sustainability"]
    limit: 50
    sort_type: "hot"  # hot, new, top, rising
```

### Flux RSS
```yaml
collectors:
  rss:
    enabled: true
    feeds:
      - url: "https://example.com/feed/"
        name: "Example News"
```

### Planification
```yaml
schedule:
  interval: 3600  # Collecte toutes les heures
```

## ğŸ”„ Automatisation

### Avec cron (Linux/macOS)
```bash
# Collecte toutes les heures
0 * * * * cd /path/to/info-watchdog && python run.py

# Logs
0 * * * * cd /path/to/info-watchdog && python run.py >> logs/cron.log 2>&1
```

### Avec Task Scheduler (Windows)
1. Ouvrez le Planificateur de tÃ¢ches
2. CrÃ©ez une tÃ¢che de base
3. DÃ©clencheur : Quotidien/Horaire
4. Action : `python.exe /path/to/InfoWatchdog/run.py`

## ğŸ“‹ Structure du Projet

```
info-watchdog/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Gestionnaire principal
â”‚   â”œâ”€â”€ collectors/          # Collecteurs de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ base_collector.py
â”‚   â”‚   â”œâ”€â”€ reddit_collector.py
â”‚   â”‚   â””â”€â”€ rss_collector.py
â”‚   â”œâ”€â”€ storage/             # SystÃ¨mes de stockage
â”‚   â”‚   â”œâ”€â”€ base_storage.py
â”‚   â”‚   â””â”€â”€ airtable_storage.py
â”‚   â””â”€â”€ utils/               # Utilitaires
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yml           # Configuration principale
â”‚   â””â”€â”€ keywords.json        # Mots-clÃ©s environnementaux
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ run.py                   # Script de lancement
â”œâ”€â”€ .env.example            # Template variables d'environnement
â””â”€â”€ README.md               # Documentation
```

## ğŸ› Choix Techniques

### Architecture Modulaire
- **Collecteurs** : Facilement extensibles pour nouvelles sources
- **Stockage** : Interface abstraite (Airtable, Google Sheets, etc.)
- **Configuration** : YAML pour simplicitÃ© et lisibilitÃ©

### Gestion des Doublons
- Hash MD5 basÃ© sur titre + URL
- Cache en mÃ©moire pour performances
- VÃ©rification avant stockage

### Filtrage Intelligent
- Mots-clÃ©s environnementaux prÃ©dÃ©finis
- Exclusion des contenus non-pertinents
- MÃ©tadonnÃ©es spÃ©cifiques par source

### Robustesse
- Gestion d'erreur par collecteur
- Logs dÃ©taillÃ©s
- Tests de connexion
- Traitement par lots

## ğŸ“ˆ MÃ©triques et Monitoring

Le systÃ¨me fournit :
- Nombre d'articles collectÃ©s par cycle
- RÃ©partition par source
- Taux de rÃ©ussite du stockage
- DurÃ©e des cycles de collecte
- Statistiques de doublons

## ğŸ”§ DÃ©veloppement

### Ajouter un nouveau collecteur
1. HÃ©riter de `BaseCollector`
2. ImplÃ©menter la mÃ©thode `collect()`
3. Ajouter la configuration dans `config.yml`
4. Enregistrer dans `main.py`

### Ajouter un nouveau systÃ¨me de stockage
1. HÃ©riter de `BaseStorage`
2. ImplÃ©menter les mÃ©thodes abstraites
3. Ajouter la configuration

## ğŸ“ Logs

Les logs sont sauvegardÃ©s dans `infowatchdog.log` avec :
- Horodatage
- Niveau (INFO, ERROR, WARNING)
- Source (collector, storage)
- Message dÃ©taillÃ©

## ğŸ› DÃ©pannage

### Erreur Reddit API
- VÃ©rifiez vos credentials dans `.env`
- Respectez les limites de taux Reddit

### Erreur Airtable
- VÃ©rifiez votre API key et Base ID
- Assurez-vous que la table a tous les champs requis

### Aucun article collectÃ©
- VÃ©rifiez la connectivitÃ© internet
- Testez avec `--test-only`
- Consultez les logs

## ğŸ“„ Licence

MIT License - Voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/amazing-feature`)
3. Committez vos changements (`git commit -m 'Add amazing feature'`)
4. Push sur la branche (`git push origin feature/amazing-feature`)
5. Ouvrez une Pull Request